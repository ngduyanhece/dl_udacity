{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### my own implementation of the cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def init_weight_and_bias(M1,M2):\n",
    "    W = np.random.randn(M1,M2) / np.sqrt(M1 + M2)\n",
    "    b = np.zeros(M2)\n",
    "    return W.astype(np.float32), b.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape(\n",
    "        (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self,M1,M2,an_id):\n",
    "        self.id = an_id\n",
    "        self.M1 = M1\n",
    "        self.M2 = M2\n",
    "        W,b = init_weight_and_bias(M1,M2)\n",
    "        self.W = tf.Variable(W)\n",
    "        self.b = tf.Variable(b)\n",
    "        self.params = [self.W,self.b]\n",
    "    def forward(self,X):\n",
    "        return tf.nn.relu(tf.matmul(X,self.W) + self.b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ConvPoolLayer(object):\n",
    "    def __init__(self,mi,mo,fw=5,fh=5,poolsz=(2,2),padding='SAME'):\n",
    "        self.W = tf.Variable(tf.truncated_normal([fw,fh,mi,mo],stddev=0.1))\n",
    "        self.b = tf.Variable(tf.zeros([mo]))\n",
    "        self.poolsz = poolsz\n",
    "        self.params = [self.W,self.b]\n",
    "        self.padding = padding\n",
    "    def forward(self,X,strides=[1,1,1,1]):\n",
    "        conv_out = tf.nn.conv2d(X,self.W,strides=strides,padding='SAME')\n",
    "        conv_out = tf.nn.bias_add(conv_out,self.b)\n",
    "        p1,p2 = self.poolsz\n",
    "        pool_out = tf.nn.max_pool(\n",
    "            conv_out,\n",
    "            ksize = [1,p1,p2,1],\n",
    "            strides = [1,p1,p2,1],\n",
    "            padding = self.padding\n",
    "        )\n",
    "        return tf.nn.relu(pool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self,convpool_layer_sizes,hidden_layer_sizes):\n",
    "        self.convpool_layer_sizes = convpool_layer_sizes\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        \n",
    "    def train(self,X,Y,X_valid = None,Y_valid = None, lr=10e-4, mu=0.99, reg=10e-4, decay=0.99999, eps=10e-3, batch_sz=30, epochs=3, show_fig=True):\n",
    "        #convert hyper-parameter to np.float32\n",
    "        lr = np.float32(lr)\n",
    "        mu = np.float32(mu)\n",
    "        reg = np.float32(reg)\n",
    "        decay = np.float32(decay)\n",
    "        eps = np.float32(eps)\n",
    "        K = 10\n",
    "        X, Y = shuffle(X, Y)\n",
    "        X = X.astype(np.float32)\n",
    "        Y = Y.astype(np.float32)\n",
    "        # initialize convpool layers\n",
    "        N,w,h,c = X.shape\n",
    "        mi = c\n",
    "        outw = w\n",
    "        outh = h\n",
    "        self.convpool_layers = []\n",
    "        for mo,fw,fh in self.convpool_layer_sizes:\n",
    "            layer = ConvPoolLayer(mi,mo,fw,fh)\n",
    "            mi = mo \n",
    "            outw = outw / 2\n",
    "            outh = outh / 2\n",
    "            self.convpool_layers.append(layer)\n",
    "        self.hidden_layers = []\n",
    "        M1 = self.convpool_layer_sizes[-1][0]*outw*outh\n",
    "        count = 0\n",
    "        for M2 in self.hidden_layer_sizes:\n",
    "            hidden = HiddenLayer(M1,M2,count)\n",
    "            self.hidden_layers.append(hidden)\n",
    "            M1 = M2\n",
    "            count += 1\n",
    "        #logistic regression layer\n",
    "        W,b = init_weight_and_bias(M1,K)\n",
    "        self.W = tf.Variable(W,'W_logreg')\n",
    "        self.b = tf.Variable(b,'b_logreg')\n",
    "        self.params = [self.W,self.b]\n",
    "        for c_layer in self.convpool_layers:\n",
    "            self.params += c_layer.params\n",
    "        for h_layer in self.hidden_layers:\n",
    "            self.params += h_layer.params\n",
    "        #set up variables for tensorflow\n",
    "        tf_X_train = tf.placeholder(tf.float32,shape=(None,w,h,c))\n",
    "        tf_Y_train = tf.placeholder(tf.float32,shape=(None,K))\n",
    "        logits = self.forward(tf_X_train)\n",
    "        r_cost = reg*np.sum([tf.nn.l2_loss(p) for p in self.params])\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_Y_train,logits=logits))\n",
    "        loss = cost + r_cost\n",
    "        prediction = self.predict(tf_X_train)\n",
    "        train_op = tf.train.RMSPropOptimizer(lr, decay=decay, momentum=mu).minimize(loss)\n",
    "        n_batches = N / batch_sz\n",
    "        train_costs = []\n",
    "        valid_costs = []\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as session:\n",
    "            session.run(init)\n",
    "            for epoch in xrange(epochs):\n",
    "                X,Y = shuffle(X,Y)\n",
    "                for j in xrange(n_batches):\n",
    "                    X_batch = X[j*batch_sz: (j*batch_sz + batch_sz)]\n",
    "                    Y_batch = Y[j*batch_sz: (j*batch_sz + batch_sz)]\n",
    "                    session.run(train_op,feed_dict={tf_X_train:X_batch,tf_Y_train:Y_batch})\n",
    "                    if j % 100 == 0:\n",
    "                        if Y_valid != None:\n",
    "                            print(\"calculating valid cost:\")\n",
    "                            vc = session.run(cost, feed_dict={tf_X_train: X_valid, tf_Y_train: Y_valid})\n",
    "                            valid_costs.append(vc)\n",
    "                            pv = session.run(prediction, feed_dict={tf_X_train: X_valid, tf_Y_train: Y_valid})\n",
    "                            va = accuracy(pv,Y_valid)\n",
    "                        print(\"calculating training cost:\")\n",
    "                        tc = session.run(loss, feed_dict={tf_X_train: X_batch, tf_Y_train: Y_batch})\n",
    "                        train_costs.append(tc)\n",
    "                        pt = session.run(prediction, feed_dict={tf_X_train: X_batch, tf_Y_train: Y_batch})\n",
    "                        ta = accuracy(pt,Y_batch)\n",
    "                        print \"epoach:\", epoch, \"batch:\", j, \"nb:\", n_batches\n",
    "                        if Y_valid != None:\n",
    "                            print \"validation cost:\", vc, \"validation accuracy:\", va\n",
    "                        print \"training cost:\", tc, \"training accuracy:\", ta\n",
    "        if show_fig:\n",
    "            plt.plot(train_costs)\n",
    "            plt.plot(valid_costs)\n",
    "            plt.show()\n",
    "    def forward(self,X):\n",
    "        Z = X\n",
    "        for c in self.convpool_layers:\n",
    "            Z = c.forward(Z)\n",
    "        #fully connected layer \n",
    "        Z_shape = Z.get_shape().as_list()\n",
    "        Z = tf.reshape(Z, [-1, np.prod(Z_shape[1:])])\n",
    "        for h in self.hidden_layers:\n",
    "            Z = h.forward(Z)\n",
    "        return tf.matmul(Z,self.W) + self.b\n",
    "    def predict(self,X):\n",
    "        logits = self.forward(X)\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (200000, 28, 28), (200000,))\n",
      "('Validation set', (10000, 28, 28), (10000,))\n",
      "('Test set', (10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (200000, 28, 28, 1), (200000, 10))\n",
      "('Validation set', (10000, 28, 28, 1), (10000, 10))\n",
      "('Test set', (10000, 28, 28, 1), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = CNN(\n",
    "    convpool_layer_sizes=[(64, 11, 11), (20, 5, 5)],\n",
    "    hidden_layer_sizes=[500, 300],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating training cost:\n",
      "epoach: 0 batch: 0 nb: 1562\n",
      "training cost: 2.86656 training accuracy: 4.6875\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 100 nb: 1562\n",
      "training cost: 1.42224 training accuracy: 82.03125\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 200 nb: 1562\n",
      "training cost: 0.843455 training accuracy: 85.9375\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 300 nb: 1562\n",
      "training cost: 0.942121 training accuracy: 83.59375\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 400 nb: 1562\n",
      "training cost: 0.680147 training accuracy: 93.75\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 500 nb: 1562\n",
      "training cost: 0.747414 training accuracy: 91.40625\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 600 nb: 1562\n",
      "training cost: 0.867894 training accuracy: 86.71875\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 700 nb: 1562\n",
      "training cost: 0.825948 training accuracy: 86.71875\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 800 nb: 1562\n",
      "training cost: 0.75842 training accuracy: 89.0625\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 900 nb: 1562\n",
      "training cost: 0.64637 training accuracy: 90.625\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 1000 nb: 1562\n",
      "training cost: 0.739849 training accuracy: 89.84375\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 1100 nb: 1562\n",
      "training cost: 0.765736 training accuracy: 89.84375\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 1200 nb: 1562\n",
      "training cost: 0.738456 training accuracy: 87.5\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 1300 nb: 1562\n",
      "training cost: 0.677648 training accuracy: 92.1875\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 1400 nb: 1562\n",
      "training cost: 0.707206 training accuracy: 89.84375\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 1500 nb: 1562\n",
      "training cost: 0.765055 training accuracy: 86.71875\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141bfe250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train(train_dataset,train_labels,batch_sz=128,epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
