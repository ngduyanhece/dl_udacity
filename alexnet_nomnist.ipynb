{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight_and_bias(M1,M2):\n",
    "    W = np.random.randn(M1,M2) / np.sqrt(M1 + M2)\n",
    "    b = np.zeros(M2)\n",
    "    return W.astype(np.float32), b.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape(\n",
    "        (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self,M1,M2,an_id):\n",
    "        self.id = an_id\n",
    "        self.M1 = M1\n",
    "        self.M2 = M2\n",
    "        W,b = init_weight_and_bias(M1,M2)\n",
    "        self.W = tf.Variable(W)\n",
    "        self.b = tf.Variable(b)\n",
    "        self.params = [self.W,self.b]\n",
    "    def forward(self,X):\n",
    "        return tf.nn.relu(tf.matmul(X,self.W) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvPoolLayer(object):\n",
    "    def __init__(self,mi,mo,fw=5,fh=5,poolsz=(2,2),strides=[1,1,1,1],padding='SAME'):\n",
    "        self.W = tf.Variable(tf.truncated_normal([fw,fh,mi,mo],stddev=0.1))\n",
    "        self.b = tf.Variable(tf.zeros([mo]))\n",
    "        self.strides = strides\n",
    "        self.poolsz = poolsz\n",
    "        self.params = [self.W,self.b]\n",
    "        self.padding = padding\n",
    "    def forward(self,X):\n",
    "        conv_out = tf.nn.conv2d(X,self.W,strides=self.strides,padding='SAME')\n",
    "        conv_out = tf.nn.bias_add(conv_out,self.b)\n",
    "        p1,p2 = self.poolsz\n",
    "        pool_out = tf.nn.max_pool(\n",
    "            conv_out,\n",
    "            ksize = [1,p1,p2,1],\n",
    "            strides = [1,2,2,1],\n",
    "            padding = self.padding\n",
    "        )\n",
    "        return tf.nn.relu(pool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self,convpool_layer_sizes,hidden_layer_sizes):\n",
    "        self.convpool_layer_sizes = convpool_layer_sizes\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        \n",
    "    def train(self,X,Y,X_valid = None,Y_valid = None, lr=10e-4, mu=0.99, reg=10e-4, decay=0.99999, eps=10e-3, batch_sz=30, epochs=3, show_fig=True):\n",
    "        #convert hyper-parameter to np.float32\n",
    "        lr = np.float32(lr)\n",
    "        mu = np.float32(mu)\n",
    "        reg = np.float32(reg)\n",
    "        decay = np.float32(decay)\n",
    "        eps = np.float32(eps)\n",
    "        K = 10\n",
    "        X, Y = shuffle(X, Y)\n",
    "        X = X.astype(np.float32)\n",
    "        Y = Y.astype(np.float32)\n",
    "        # initialize convpool layers\n",
    "        N,w,h,c = X.shape\n",
    "        mi = c\n",
    "        outw = 2\n",
    "        outh = 2\n",
    "        self.convpool_layers = []\n",
    "        for mo,fw,fh,ps,st in self.convpool_layer_sizes:\n",
    "            layer = ConvPoolLayer(mi,mo,fw,fh,ps,st)\n",
    "            mi = mo \n",
    "            self.convpool_layers.append(layer)\n",
    "        self.hidden_layers = []\n",
    "        M1 = self.convpool_layer_sizes[-1][0]*outw*outh\n",
    "        count = 0\n",
    "        for M2 in self.hidden_layer_sizes:\n",
    "            hidden = HiddenLayer(M1,M2,count)\n",
    "            self.hidden_layers.append(hidden)\n",
    "            M1 = M2\n",
    "            count += 1\n",
    "        #logistic regression layer\n",
    "        W,b = init_weight_and_bias(M1,K)\n",
    "        self.W = tf.Variable(W,'W_logreg')\n",
    "        self.b = tf.Variable(b,'b_logreg')\n",
    "        self.params = [self.W,self.b]\n",
    "        for c_layer in self.convpool_layers:\n",
    "            self.params += c_layer.params\n",
    "        for h_layer in self.hidden_layers:\n",
    "            self.params += h_layer.params\n",
    "        #set up variables for tensorflow\n",
    "        tf_X_train = tf.placeholder(tf.float32,shape=(None,w,h,c))\n",
    "        tf_Y_train = tf.placeholder(tf.float32,shape=(None,K))\n",
    "        logits = self.forward(tf_X_train)\n",
    "        r_cost = reg*np.sum([tf.nn.l2_loss(p) for p in self.params])\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_Y_train,logits=logits))\n",
    "        loss = cost + r_cost\n",
    "        prediction = self.predict(tf_X_train)\n",
    "        train_op = tf.train.RMSPropOptimizer(lr, decay=decay, momentum=mu).minimize(loss)\n",
    "        n_batches = N / batch_sz\n",
    "        train_costs = []\n",
    "        valid_costs = []\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as session:\n",
    "            session.run(init)\n",
    "            for epoch in xrange(epochs):\n",
    "                X,Y = shuffle(X,Y)\n",
    "                for j in xrange(n_batches):\n",
    "                    X_batch = X[j*batch_sz: (j*batch_sz + batch_sz)]\n",
    "                    Y_batch = Y[j*batch_sz: (j*batch_sz + batch_sz)]\n",
    "                    session.run(train_op,feed_dict={tf_X_train:X_batch,tf_Y_train:Y_batch})\n",
    "                    if j % 5 == 0:\n",
    "                        if Y_valid != None:\n",
    "                            print(\"calculating valid cost:\")\n",
    "                            vc = session.run(cost, feed_dict={tf_X_train: X_valid, tf_Y_train: Y_valid})\n",
    "                            valid_costs.append(vc)\n",
    "                            pv = session.run(prediction, feed_dict={tf_X_train: X_valid, tf_Y_train: Y_valid})\n",
    "                            va = accuracy(pv,Y_valid)\n",
    "                        print(\"calculating training cost:\")\n",
    "                        tc = session.run(loss, feed_dict={tf_X_train: X_batch, tf_Y_train: Y_batch})\n",
    "                        train_costs.append(tc)\n",
    "                        pt = session.run(prediction, feed_dict={tf_X_train: X_batch, tf_Y_train: Y_batch})\n",
    "                        ta = accuracy(pt,Y_batch)\n",
    "                        print \"epoach:\", epoch, \"batch:\", j, \"nb:\", n_batches\n",
    "                        if Y_valid != None:\n",
    "                            print \"validation cost:\", vc, \"validation accuracy:\", va\n",
    "                        print \"training cost:\", tc, \"training accuracy:\", ta\n",
    "        if show_fig:\n",
    "            plt.plot(train_costs)\n",
    "            plt.plot(valid_costs)\n",
    "            plt.show()\n",
    "    def forward(self,X):\n",
    "        Z = X\n",
    "        for c in self.convpool_layers:\n",
    "            Z = c.forward(Z)\n",
    "        #fully connected layer \n",
    "        Z_shape = Z.get_shape().as_list()\n",
    "        Z = tf.reshape(Z, [-1, np.prod(Z_shape[1:])])\n",
    "        for h in self.hidden_layers:\n",
    "            Z = h.forward(Z)\n",
    "        return tf.matmul(Z,self.W) + self.b\n",
    "    def predict(self,X):\n",
    "        logits = self.forward(X)\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (200000, 28, 28), (200000,))\n",
      "('Validation set', (10000, 28, 28), (10000,))\n",
      "('Test set', (10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (200000, 28, 28, 1), (200000, 10))\n",
      "('Validation set', (10000, 28, 28, 1), (10000, 10))\n",
      "('Test set', (10000, 28, 28, 1), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CNN(\n",
    "    convpool_layer_sizes=[\n",
    "        (64, 11, 11,(3,3),[1,4,4,1]), \n",
    "        (192, 64, 64,(3,3),[1,1,1,1])\n",
    "    ],\n",
    "    hidden_layer_sizes=[500, 300],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating training cost:\n",
      "epoach: 0 batch: 0 nb: 1562\n",
      "training cost: 197.208 training accuracy: 10.9375\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 5 nb: 1562\n",
      "training cost: 197.056 training accuracy: 15.625\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 10 nb: 1562\n",
      "training cost: 197.058 training accuracy: 12.5\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 15 nb: 1562\n",
      "training cost: 196.988 training accuracy: 25.0\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 20 nb: 1562\n",
      "training cost: 196.832 training accuracy: 34.375\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 25 nb: 1562\n",
      "training cost: 196.74 training accuracy: 24.21875\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 30 nb: 1562\n",
      "training cost: 196.634 training accuracy: 40.625\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 35 nb: 1562\n",
      "training cost: 196.545 training accuracy: 41.40625\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 40 nb: 1562\n",
      "training cost: 196.317 training accuracy: 56.25\n",
      "calculating training cost:\n",
      "epoach: 0 batch: 45 nb: 1562\n",
      "training cost: 196.174 training accuracy: 50.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-395f837fba88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-d01205b10f7f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y, X_valid, Y_valid, lr, mu, reg, decay, eps, batch_sz, epochs, show_fig)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_sz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_sz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtf_X_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf_Y_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mY_valid\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adnguyen/env/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adnguyen/env/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adnguyen/env/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/adnguyen/env/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adnguyen/env/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(train_dataset,train_labels,batch_sz=128,epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
